{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_only_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iQPZzK4zvxA",
        "outputId": "ede345bc-c90f-4b25-860e-012c3bdc21dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf runs.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrqXct6V0zkR",
        "outputId": "82705cc6-a12b-4bb8-c1f5-29e1682b7ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "runs/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_val/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_val/events.out.tfevents.1654801127.44eacb9e064a.8648.3\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_train/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_train/events.out.tfevents.1654801126.44eacb9e064a.8648.2\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Loss_train/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Loss_train/events.out.tfevents.1654801126.44eacb9e064a.8648.1\n",
            "runs/Jun09_18-54-32_44eacb9e064a/events.out.tfevents.1654800874.44eacb9e064a.8648.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "AhlJUDqHzgno",
        "outputId": "0da7600a-1f8b-4b80-8f88-12a35fb57d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id', 'label']\n",
            "['0_train_rec18_pos3', '1']\n",
            "['id', 'label']\n",
            "['6716_val_rec27_pos4', '1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:72: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6711, 300, 128])\n",
            "torch.Size([6711])\n",
            "torch.Size([2853, 300, 128])\n",
            "torch.Size([2853])\n",
            "148858757\n",
            "[205/0] loss: 0.730956, accuracy: 50.061\n",
            "Accuracy of the network on the validation: 54.81481481481482 %\n",
            "loss of the network on the validation: 0.7270519137382507 \n",
            "best model with val acc 54.81481481481482is saved\n",
            "[205/1] loss: 0.739901, accuracy: 48.875\n",
            "Accuracy of the network on the validation: 54.074074074074076 %\n",
            "loss of the network on the validation: 0.7630759477615356 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a6d7a3deb718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# print(f'labels.shape:{labels.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# print(f'correct_pre:{correct}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;31m# print(f'predicted:{predicted}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# print(f'correct:{correct}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import csv\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "#set random seeds\n",
        "seed=42\n",
        "torch.manual_seed(seed)\n",
        "writer = SummaryWriter()\n",
        "# Device configuration\n",
        "device = torch.device('cuda')\n",
        "# Hyper-parameters \n",
        "# input_size = 784 # 28x28\n",
        "num_classes = 1\n",
        "num_epochs = 300\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "input_size = 128\n",
        "sequence_length = 300\n",
        "hidden_size = 3500\n",
        "num_layers = 2\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "#                                           batch_size=batch_size, \n",
        "#                                           shuffle=False)\n",
        "org_path = os.getcwd()\n",
        "#read csv\n",
        "rows = []\n",
        "rows_test = []\n",
        "with open(\"/content/bc_detection_train.csv\", 'r') as file:\n",
        "    csvreader = csv.reader(file)\n",
        "    header = next(csvreader)\n",
        "    for row_1 in csvreader:\n",
        "        rows.append(row_1)\n",
        "print(header)\n",
        "print(rows[:][0])\n",
        "with open(\"/content/bc_detection_val.csv\", 'r') as file:\n",
        "    csvreader = csv.reader(file)\n",
        "    header = next(csvreader)\n",
        "    for row_2 in csvreader:\n",
        "        rows_test.append(row_2)\n",
        "print(header)\n",
        "print(rows_test[:][0])\n",
        "\n",
        "#reading input data\n",
        "#path = os.getcwd() + '/' + 'resnet50'\n",
        "path = '/content/drive/MyDrive/audio_features_train_latest'\n",
        "dir_list = os.listdir(path)\n",
        "os.chdir(path)\n",
        "\n",
        "combined_data = np.array([np.load(fname[0]+'_audio_vggish.npy') for fname in rows])\n",
        "#combined_data = np.array([print(fname[0]+'_audio_vggish.npy') if ((np.load(fname[0]+'_audio_vggish.npy').shape) != (300,128)) else 0 for fname in rows ])\n",
        "labels = np.array([np.array(fname[1], dtype=np.float16) for fname in rows])\n",
        "path = '/content/drive/MyDrive/audio_features_val'\n",
        "dir_list = os.listdir(path)\n",
        "os.chdir(path)\n",
        "combined_data_test = np.array([np.load(fname[0]+'_audio_vggish.npy') for fname in rows_test])\n",
        "#combined_data_test = np.array([print(fname[0]+'_audio_vggish.npy') if ((np.load(fname[0]+'_audio_vggish.npy').shape) != (300,128)) else 0 for fname in rows_test ])\n",
        "labels_test = np.array([np.array(fname[1], dtype=np.float16) for fname in rows_test])\n",
        "os.chdir(org_path)\n",
        "\n",
        "tensor_x = torch.Tensor(combined_data) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(labels.astype(np.float))\n",
        "\n",
        "tensor_x_test = torch.Tensor(combined_data_test) # transform to torch tensor\n",
        "tensor_y_test = torch.Tensor(labels_test.astype(np.float))\n",
        "my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "dataset_train, dataset_validate = train_test_split(\n",
        "        my_dataset, test_size=0.02, random_state=84\n",
        "    )\n",
        "my_dataset_test = TensorDataset(tensor_x_test,tensor_y_test)\n",
        "print(tensor_x.shape)\n",
        "print(tensor_y.shape)\n",
        "print(tensor_x_test.shape)\n",
        "print(tensor_y_test.shape)\n",
        "my_dataloader = DataLoader(dataset_train,batch_size=batch_size, shuffle = True) # create your dataloader\n",
        "my_dataloader_val = DataLoader(dataset_validate,batch_size=batch_size) \n",
        "my_dataloader_test = DataLoader(my_dataset_test,batch_size=batch_size) \n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps,\n",
        "    num_training_steps,\n",
        "    num_cycles=7.0 / 16.0,\n",
        "    last_epoch=-1,\n",
        "):\n",
        "    def _lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        no_progress = float(current_step - num_warmup_steps) / float(\n",
        "            max(1, num_training_steps - num_warmup_steps)\n",
        "        )\n",
        "        return max(0.0, math.cos(math.pi * num_cycles * no_progress))\n",
        "    return LambdaLR(optimizer, _lr_lambda, last_epoch)\n",
        "\n",
        "# for i, (images, labels) in enumerate(my_dataloader): \n",
        "#   print(images.shape)\n",
        "#   print(labels)\n",
        "#Fully connected neural network with one hidden layer\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        #self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # -> x needs to be: (batch_size, seq, input_size)\n",
        "        \n",
        "        # or:\n",
        "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.lynm = nn.LayerNorm(input_size)\n",
        "        self.lynm1 = nn.LayerNorm(hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Set initial hidden states (and cell states for LSTM)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "        h0 = torch.nn.init.xavier_normal_(h0).to(device) \n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "        c0 = torch.nn.init.xavier_normal_(c0).to(device)\n",
        "        \n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        \n",
        "        # Forward propagate RNN\n",
        "        #out, _ = self.rnn(x, h0)  \n",
        "        # or:\n",
        "        x= self.lynm(x)\n",
        "        out, _ = self.lstm(x, (h0,c0))  \n",
        "        \n",
        "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        # out: (n, 28, 128)\n",
        "        # print(\"out bef\")\n",
        "        # print(out)\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "       \n",
        "        # out: (n, 128)\n",
        "        x= self.lynm1(out) \n",
        "        out = self.fc(x)\n",
        "\n",
        "        # print(\"out aft\")\n",
        "        # print(out)\n",
        "        # out: (n, 10)\n",
        "        return torch.sigmoid(out)\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "# Loss and optimizer\n",
        "\n",
        "# for name, param in model.named_parameters():\n",
        "#   if 'bias' in name:\n",
        "#      nn.init.constant(param, 0.0)\n",
        "#   elif 'weight' in name:\n",
        "#      nn.init.xavier_normal(param)\n",
        "\n",
        "def count_parameters(model):\n",
        "\n",
        " return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "s = count_parameters(model)\n",
        "\n",
        "print(s)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay= 0.0005)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9)  \n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer, 500, 402660\n",
        "    )\n",
        "# Train the model\n",
        "n_total_steps = len(my_dataloader)\n",
        "best_val_acc = 0\n",
        "for epoch in range(num_epochs):\n",
        "    correct = 0\n",
        "    num_samples = 0\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(my_dataloader):\n",
        "        # origin shape: [N, 1, 28, 28]\n",
        "        # resized: [N, 300, 2048][N,300,128]\n",
        "        \n",
        "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "        # print(images.shape)\n",
        "        labels = labels.to(device)\n",
        "        num_samples+=labels.size(0)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        # print(f'outputs.shape:{outputs.shape}')\n",
        "        # print(labels.shape)\n",
        "        # outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, labels.unsqueeze(1))\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        predicted = (outputs > 0.5).long()\n",
        "        # print(f'predicted.shape:{predicted.shape}')\n",
        "        # print(f'labels.shape:{labels.shape}')\n",
        "        # print(f'correct_pre:{correct}')\n",
        "        correct += (predicted.squeeze()== labels).sum().item()\n",
        "        # print(f'predicted:{predicted}')\n",
        "        # print(f'correct:{correct}')\n",
        "        # print(f'labels.size:{labels.size(0)}')\n",
        "        # if (i+1) % 1 == 0:\n",
        "        #     print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "        # print(f'correct:{correct}')\n",
        "    # print(f'tensor_y.size(0):{tensor_y.size(0)}')\n",
        "    print('[%d/%d] loss: %f, accuracy: %.3f' %\n",
        "          (i , epoch, loss.item(), 100 * correct /num_samples))\n",
        "    writer.add_scalars('Loss',{'train':loss.item()},epoch)\n",
        "    writer.add_scalars('Accuracy', {'train': 100 * correct /num_samples},epoch)\n",
        "        \n",
        "    # Test the model\n",
        "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "    num_samples_val = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct_val = 0\n",
        "        for i, (images, labels) in enumerate(my_dataloader_val):\n",
        "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "            labels = labels.to(device)\n",
        "            num_samples_val+=labels.size(0)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels.unsqueeze(1))\n",
        "            predicted = (outputs > 0.5).long()\n",
        "            correct_val += (predicted.squeeze()== labels).sum().item()\n",
        "        val_acc = 100 * correct_val / num_samples_val\n",
        "        print(f'Accuracy of the network on the validation: {val_acc} %')\n",
        "        print(f'loss of the network on the validation: {loss} ')\n",
        "        writer.add_scalars('loss', {'val': loss},epoch)\n",
        "    if(val_acc> best_val_acc):\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(),'./best_model'+'_'+str(learning_rate)+'_'+str(num_layers)+'.ckpt')                         \n",
        "        print(\"best model with val acc \"+ str(best_val_acc)+ \"is saved\")\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load('/content/best_model'+'_'+str(learning_rate)+'_'+str(num_layers)+'.ckpt'))   \n",
        "with torch.no_grad():\n",
        "        correct_val = 0\n",
        "        num_samples_val = 0\n",
        "        for i, (images, labels) in enumerate(my_dataloader_test):\n",
        "            images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "            labels = labels.to(device)\n",
        "            num_samples_val+=labels.size(0)\n",
        "            outputs = model(images)\n",
        "            predicted = (outputs > 0.5).long()\n",
        "            correct_val += (predicted.squeeze()== labels).sum().item()\n",
        "        val_acc = 100 * correct_val / num_samples_val\n",
        "        print(f'Accuracy of the network on the test: {val_acc} %')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "ufkXcUTBzxPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar cvzf runs.tar.gz runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uAaLjViAyzs",
        "outputId": "1ca436ed-c813-4b98-a2fd-e87b8d050a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "runs/\n",
            "runs/Jun10_18-36-20_ef20d790990e/\n",
            "runs/Jun10_18-36-20_ef20d790990e/Loss_train/\n",
            "runs/Jun10_18-36-20_ef20d790990e/Loss_train/events.out.tfevents.1654886780.ef20d790990e.81.2\n",
            "runs/Jun10_18-36-20_ef20d790990e/Accuracy_val/\n",
            "runs/Jun10_18-36-20_ef20d790990e/Accuracy_val/events.out.tfevents.1654886784.ef20d790990e.81.4\n",
            "runs/Jun10_18-36-20_ef20d790990e/Accuracy_train/\n",
            "runs/Jun10_18-36-20_ef20d790990e/Accuracy_train/events.out.tfevents.1654886780.ef20d790990e.81.3\n",
            "runs/Jun10_18-36-20_ef20d790990e/events.out.tfevents.1654886180.ef20d790990e.81.1\n",
            "runs/Jun09_18-54-32_44eacb9e064a/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Loss_train/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Loss_train/events.out.tfevents.1654801126.44eacb9e064a.8648.1\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_val/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_val/events.out.tfevents.1654801127.44eacb9e064a.8648.3\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_train/\n",
            "runs/Jun09_18-54-32_44eacb9e064a/Accuracy_train/events.out.tfevents.1654801126.44eacb9e064a.8648.2\n",
            "runs/Jun09_18-54-32_44eacb9e064a/events.out.tfevents.1654800874.44eacb9e064a.8648.0\n",
            "runs/Jun10_18-27-27_ef20d790990e/\n",
            "runs/Jun10_18-27-27_ef20d790990e/events.out.tfevents.1654885650.ef20d790990e.81.0\n"
          ]
        }
      ]
    }
  ]
}